{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = ['sieun', 'yoon', 'chaewon','olivia hye','jisoo','lisa','jennie','rose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdolDataset(Dataset):\n",
    "    def __init__(self,data_path,setting,transform):\n",
    "        self.setting = setting\n",
    "        self.transform = transform\n",
    "        self.x_data = []\n",
    "        self.y_data = []\n",
    "\n",
    "        for member in members:\n",
    "            list_dir = os.path.join(data_path, setting, member)\n",
    "            for name in os.listdir(list_dir):\n",
    "                img_dir = os.path.join(list_dir,name)\n",
    "        \n",
    "                if setting == 'train':\n",
    "                    for i in range(10):\n",
    "                        self.x_data.append(img_dir)\n",
    "                        self.y_data.append(members.index(member))\n",
    "\n",
    "                if setting == 'valid' or setting == 'test':\n",
    "                    self.x_data.append(img_dir)\n",
    "                    self.y_data.append(members.index(member))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.x_data[index])\n",
    "        x = self.transform(img)\n",
    "        y = self.y_data[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "  transforms.RandomResizedCrop(224),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.RandomRotation(45),\n",
    "  transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "  transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"\"\n",
    "train_set = IdolDataset(data_path, 'train', train_transform)\n",
    "train_dataloader = DataLoader(train_set, batch_size = 64, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc6b6a04635e20915b4648c6f217826c28483abed9316364b3178afc03ed9a19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

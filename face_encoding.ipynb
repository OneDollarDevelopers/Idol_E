{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/team_project\n","!pwd\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnLSYwo8L7K0","executionInfo":{"status":"ok","timestamp":1669457215403,"user_tz":-540,"elapsed":2790,"user":{"displayName":"김동현","userId":"09001308430709368510"}},"outputId":"2c4f0536-1db1-4b2b-f9d2-9d65f5051c85"},"id":"CnLSYwo8L7K0","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive/MyDrive/team_project\n","/gdrive/MyDrive/team_project\n"]}]},{"cell_type":"code","source":["!pip install imutils\n","!pip install face_recognition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Y2X9l6LMQzY","executionInfo":{"status":"ok","timestamp":1669457220787,"user_tz":-540,"elapsed":5389,"user":{"displayName":"김동현","userId":"09001308430709368510"}},"outputId":"cb58c249-8a3e-4526-a42a-02a03bbda6cc"},"id":"8Y2X9l6LMQzY","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.24.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.6)\n"]}]},{"cell_type":"code","execution_count":19,"id":"605c1334-bfc4-48b0-832f-8328914fbcbc","metadata":{"id":"605c1334-bfc4-48b0-832f-8328914fbcbc","executionInfo":{"status":"ok","timestamp":1669457220788,"user_tz":-540,"elapsed":6,"user":{"displayName":"김동현","userId":"09001308430709368510"}}},"outputs":[],"source":["import time\n","\n","from imutils import paths\n","import face_recognition\n","import pickle\n","import cv2\n","import os\n","import easydict"]},{"cell_type":"code","execution_count":20,"id":"5983b7f6-d3ae-4be4-8ab6-135aaf95bf95","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5983b7f6-d3ae-4be4-8ab6-135aaf95bf95","executionInfo":{"status":"ok","timestamp":1669457222500,"user_tz":-540,"elapsed":1717,"user":{"displayName":"김동현","userId":"09001308430709368510"}},"outputId":"6b06caf4-2591-47ac-f0c0-1f11c1af22fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] quantifying faces...\n","[INFO] processing image [lisa] 1/56\n","[INFO] processing image [lisa] 2/56\n","[INFO] processing image [lisa] 3/56\n","[INFO] processing image [lisa] 4/56\n","[INFO] processing image [lisa] 5/56\n","[INFO] processing image [lisa] 6/56\n","[INFO] processing image [lisa] 7/56\n","[INFO] processing image [lisa] 8/56\n","[INFO] processing image [jisoo] 9/56\n","[INFO] processing image [jisoo] 10/56\n","[INFO] processing image [jisoo] 11/56\n","[INFO] processing image [jisoo] 12/56\n","[INFO] processing image [jisoo] 13/56\n","[INFO] processing image [jisoo] 14/56\n","[INFO] processing image [jisoo] 15/56\n","[INFO] processing image [jisoo] 16/56\n","[INFO] processing image [yoon] 17/56\n","[INFO] processing image [yoon] 18/56\n","[INFO] processing image [yoon] 19/56\n","[INFO] processing image [yoon] 20/56\n","[INFO] processing image [yoon] 21/56\n","[INFO] processing image [yoon] 22/56\n","[INFO] processing image [yoon] 23/56\n","[INFO] processing image [yoon] 24/56\n","[INFO] processing image [olivia hye] 25/56\n","[INFO] processing image [olivia hye] 26/56\n","[INFO] processing image [olivia hye] 27/56\n","[INFO] processing image [olivia hye] 28/56\n","[INFO] processing image [olivia hye] 29/56\n","[INFO] processing image [olivia hye] 30/56\n","[INFO] processing image [olivia hye] 31/56\n","[INFO] processing image [olivia hye] 32/56\n","[INFO] processing image [rose] 33/56\n","[INFO] processing image [rose] 34/56\n","[INFO] processing image [rose] 35/56\n","[INFO] processing image [rose] 36/56\n","[INFO] processing image [rose] 37/56\n","[INFO] processing image [rose] 38/56\n","[INFO] processing image [rose] 39/56\n","[INFO] processing image [rose] 40/56\n","[INFO] processing image [chaewon] 41/56\n","[INFO] processing image [chaewon] 42/56\n","[INFO] processing image [chaewon] 43/56\n","[INFO] processing image [chaewon] 44/56\n","[INFO] processing image [chaewon] 45/56\n","[INFO] processing image [chaewon] 46/56\n","[INFO] processing image [chaewon] 47/56\n","[INFO] processing image [chaewon] 48/56\n","[INFO] processing image [jennie] 49/56\n","[INFO] processing image [jennie] 50/56\n","[INFO] processing image [jennie] 51/56\n","[INFO] processing image [jennie] 52/56\n","[INFO] processing image [jennie] 53/56\n","[INFO] processing image [jennie] 54/56\n","[INFO] processing image [jennie] 55/56\n","[INFO] processing image [jennie] 56/56\n","Encoding dataset took: 0.02042875289916992 minutes\n","[INFO] serializing encodings...\n"]}],"source":["\n","opt = easydict.EasyDict({\n","    \"dataset\": \"/gdrive/MyDrive/team_project/train\",\n","    \"encodings_file\": 'encodings/facencodings.pkl',\n","    \"detection_method\": \"cnn\"\n","})\n","\n","def get_command_line_args():\n","    args = vars(opt)\n","\n","    return args['dataset'],args['encodings_file'],args['detection_method']\n","\n","dataset, encodings_file, detection_method = get_command_line_args()\n","\n","# grab the paths to the input images in our dataset\n","print(\"[INFO] quantifying faces...\")\n","imagePaths = list(paths.list_images(dataset))\n","\n","# initialize the list of known encodings and known names\n","knownEncodings = []\n","knownNames = []\n","s = time.time()\n","\n","# loop over the image paths\n","for (i, imagePath) in enumerate(imagePaths):\n","    # extract the person name from the image path\n","    name = imagePath.split(os.path.sep)[-2]\n","    print(f\"[INFO] processing image [{name}] {i+1}/{len(imagePaths)}\")\n","\n","    # load the input image and convert from BGR to RGB for dlib\n","    image = cv2.imread(imagePath)\n","    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # detect the (x,y)-coordinates of the bounding boxes\n","    # corresponding to each face in the input image\n","    # we are assuming the the boxes of faces are the SAME FACE or SAME PERSON\n","    boxes = face_recognition.face_locations(rgb_image, model=detection_method)\n","\n","    # compute the facial embedding for the face\n","    # creates a vector of 128 numbers representing the face\n","    encodings = face_recognition.face_encodings(rgb_image, boxes)\n","\n","    # loop over the encodings\n","    for encoding in encodings:\n","        # add each encoding + name to our set of known names and encodings\n","        knownEncodings.append(encoding)\n","        knownNames.append(name)\n","\n","e = time.time()\n","print(f\"Encoding dataset took: {(e-s)/60} minutes\")\n","# dump the facial encodings + names to disk\n","print(\"[INFO] serializing encodings...\")\n","data = {\"encodings\": knownEncodings, \"names\": knownNames}\n","f = open(encodings_file, \"wb\")\n","f.write(pickle.dumps(data))\n","f.close()"]},{"cell_type":"code","execution_count":20,"id":"50d6cdd1-cfa6-45ac-b38e-74e80f789d38","metadata":{"id":"50d6cdd1-cfa6-45ac-b38e-74e80f789d38","executionInfo":{"status":"ok","timestamp":1669457222500,"user_tz":-540,"elapsed":3,"user":{"displayName":"김동현","userId":"09001308430709368510"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}